{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        a = torch.exp(x[:, 0]).unsqueeze(1)\n",
    "        b = torch.nn.functional.softplus(x[:, 1]).unsqueeze(1)\n",
    "        \n",
    "        res = torch.cat([a,b], dim=1)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=2, num_layers=2, device='cpu'):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "\n",
    "        self.linear = torch.nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "        out = input.view(batch_size, -1, self.input_dim)\n",
    "        out, _ = self.lstm(out, (h0, c0))  \n",
    "        \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.linear(out)\n",
    "        \n",
    "        a = torch.exp(out[:, 0]).unsqueeze(1)\n",
    "        b = torch.nn.functional.softplus(out[:, 1]).unsqueeze(1)\n",
    "        \n",
    "        out = torch.cat([a,b], dim=1)\n",
    "        \n",
    "        \n",
    "#         lstm_out, self.hidden = self.lstm(input.view(batch_size, -1, 1))\n",
    "#         y_pred = self.linear(lstm_out[-1].contiguous().view(batch_size, -1))\n",
    "        return out\n",
    "\n",
    "model = LSTM(1, 32, batch_size=batch_size, output_dim=2, num_layers=2, device=device).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "x = torch.FloatTensor(x).to(device)\n",
    "y = torch.FloatTensor(y).to(device)\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, )\n",
    "\n",
    "\n",
    "# my_dataset = utils.TensorDataset(x, y) # create your datset\n",
    "# my_dataloader = utils.DataLoader(my_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_loss(y_true, ab):\n",
    "    y_ = y_true[:, 0]\n",
    "    \n",
    "    a_ = ab[:, 0]\n",
    "    b_ = ab[:, 1]\n",
    "    \n",
    "    haz0 = ((y_ + 1e-35) / a_).pow(b_)\n",
    "    haz1 = ((y_ + 1) / a_).pow(b_)\n",
    "    \n",
    "    log_val = torch.log(torch.exp(haz1 - haz0) - 1.0)\n",
    "    \n",
    "    return -1 * (log_val - haz1).mean()\n",
    "\n",
    "def weibull_mean(a, b):\n",
    "    # Continuous mean. Theoretically at most 1 step below discretized mean \n",
    "    # E[T ] <= E[Td] + 1 true for positive distributions. \n",
    "    from scipy.special import gamma\n",
    "    return a*gamma(1.0+1.0/b)\n",
    "\n",
    "def weibull_mode(a, b):\n",
    "    # Continuous mode. \n",
    "    # TODO (mathematically) prove how close it is to discretized mode\n",
    "    mode = a*np.power((b-1.0)/b,1.0/b)\n",
    "    mode[b<=1.0]=0.0\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optim, dataloader, device):\n",
    "    loss_ar = []\n",
    "    for data_x, data_y in dataloader:\n",
    "        res = model(data_x)\n",
    "        loss = weibull_loss(data_y, res)\n",
    "        loss_ar.append(loss.item())\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optim.step()\n",
    "    return np.mean(loss_ar)\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            pred.extend(model(data).cpu().detach().numpy())\n",
    "    \n",
    "#     nums = [weibull_mean(x[0], x[1]) for x in pred]\n",
    "    nums = weibull_mode(pred[:,0], pred[:,1])\n",
    "    return sMAPE(y.squeeze(1).cpu().detach().numpy(), nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "#     loss = train_epoch(model, optim, dataloader, device)\n",
    "    smape = test(model, dataloader, device)\n",
    "    print(epoch, loss, smape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = None\n",
    "with torch.no_grad():\n",
    "    pred = model(x).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [weibull_mean(x[0], x[1]) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([8.050626543655833,\n",
       "  7.7008617161123505,\n",
       "  7.6089758059659545,\n",
       "  6.672095845386341,\n",
       "  6.5842507629710445,\n",
       "  6.566309337091586,\n",
       "  7.297705630494468,\n",
       "  7.7684387061981255,\n",
       "  8.873279097635093,\n",
       "  9.078957406321004],\n",
       " tensor([[5.],\n",
       "         [5.],\n",
       "         [7.],\n",
       "         [7.],\n",
       "         [7.],\n",
       "         [7.],\n",
       "         [7.],\n",
       "         [6.],\n",
       "         [6.],\n",
       "         [5.]]))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in power\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "nums = weibull_mode(pred[:, 0], pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.692931"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.6245165"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y.detach().numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.0077686, 5.7603803, 5.843462 , 5.393385 , 5.3903713, 5.3190107,\n",
       "        5.6041636, 5.95658  , 6.55284  , 6.952653 ], dtype=float32),\n",
       " array([[5.],\n",
       "        [5.],\n",
       "        [7.],\n",
       "        [7.],\n",
       "        [7.],\n",
       "        [7.],\n",
       "        [7.],\n",
       "        [6.],\n",
       "        [6.],\n",
       "        [5.]], dtype=float32))"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums[:10], y.detach().numpy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 7., ..., 2., 1., 3.], dtype=float32)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze(1).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.573123821491823"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sMAPE(y.squeeze(1).cpu().detach().numpy(), nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, batch_size=None, device='cpu', pv_num=None):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*2*sequence_length, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        out = x.view(batch_size, 1, x.size(1), x.size(2))\n",
    "\n",
    "        h0 = torch.zeros(2, batch_size, self.hidden_size)\n",
    "        c0 = torch.zeros(2, batch_size, self.hidden_size)\n",
    "        \n",
    "        h0 = h0.to(device)\n",
    "        c0 = c0.to(device)\n",
    "        \n",
    "        out = out.view(batch_size, -1, self.input_size)\n",
    "        out, _ = self.lstm(out, (h0, c0))  \n",
    "\n",
    "        out = out.contiguous().view(batch_size, -1)\n",
    "\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = torch.softmax(out, 1)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
